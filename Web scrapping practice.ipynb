{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import string \n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import ast\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMovieTitles(substr):\n",
    "    base_url = \"https://jsonmock.hackerrank.com/api/movies/search/?Title=\"+substr\n",
    "    soup = urllib.request.urlopen(base_url).read()\n",
    "    soup = soup.decode(\"utf-8\")\n",
    "    soup_info_dict  = ast.literal_eval(soup)\n",
    "    total_pages = soup_info_dict['total_pages']\n",
    "    title = []\n",
    "    for pages in range(1,total_pages+1):\n",
    "        url_processing = base_url+\"&page=\"+str(pages)\n",
    "        source_page = urllib.request.urlopen(url_processing).read()\n",
    "        source_page = source_page.decode(\"utf-8\")\n",
    "        soup_page_dict = ast.literal_eval(source_page)\n",
    "        data_info = soup_page_dict['data']\n",
    "        for item in data_info:\n",
    "            title.append(item['Title'])\n",
    "    title = sorted(title)\n",
    "    return title\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    _substr = str(input())\n",
    "except:\n",
    "    _substr = None\n",
    "\n",
    "res = getMovieTitles(_substr)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "base_url = \"https://jsonmock.hackerrank.com/api/movies/search/?Title=spiderman\"\n",
    "page=urllib.request.urlopen(base_url)\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "soup = soup.decode(\"utf-8\")\n",
    "soup_1=ast.literal_eval(soup)\n",
    "print(soup_1)\n",
    "total_pages=soup_1['total_pages']\n",
    "print(total_pages)\n",
    "title=[]\n",
    "for item in range(total_pages):\n",
    "    url_processing= base_url+\"&page=\"+str(item+1)\n",
    "    page_proc=urllib.request.urlopen(url_processing)\n",
    "    soup_proc=BeautifulSoup(page_proc,'html.parser')\n",
    "    soup_proc= soup_proc.decode(\"utf-8\")\n",
    "    print(type(soup_proc))\n",
    "    soup_proc=ast.literal_eval(soup_proc)\n",
    "    data=soup_proc['data']\n",
    "    for i in range(len(data)):\n",
    "        title.append(data[i]['Title'])\n",
    "title=sorted(title)        \n",
    "print(title)        \n",
    "#total_pages=total_pages_find.get_text()\n",
    "#print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://jsonmock.hackerrank.com/api/movies/search/?Title=spiderman\"\n",
    "page=urllib.request.urlopen(base_url).read()\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "total_pages=soup.get(\"total_pages\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopicCount(topic):\n",
    "    base_url = \"https://en.wikipedia.org/w/api.php?action=parse&section=0&prop=text&format=json&page=\"+str(topic)\n",
    "    soup = urllib.request.urlopen(base_url).read()\n",
    "    soup = soup.decode(\"utf-8\")\n",
    "    soup_info_dict  = ast.literal_eval(soup)\n",
    "    topic_search_info_dict = str(soup_info_dict['parse'])\n",
    "    topic_search_info = ast.literal_eval(topic_search_info_dict)\n",
    "    text_final = str(topic_search_info['text'])\n",
    "    topic_count = text_final.count(topic)\n",
    "    return topic_count\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    _topic = str(input())\n",
    "except:\n",
    "    _topic = None\n",
    "\n",
    "res = getTopicCount(_topic)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://en.wikipedia.org/w/api.php?action=parse&section=0&prop=text&format=json&page=pizza\"\n",
    "page=urllib.request.urlopen(base_url)\n",
    "for line in page:\n",
    "    print(line.decode().strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://en.wikipedia.org/w/api.php?action=parse&section=0&prop=text&format=json&page=pizza\"\n",
    "soup=urllib.request.urlopen(base_url).read()\n",
    "#soup=BeautifulSoup(page.text,'html.parser')\n",
    "#print(soup.prettify())\n",
    "soup = soup.decode(\"utf-8\")\n",
    "soup_1=ast.literal_eval(soup)\n",
    "print(soup_1)\n",
    "parsing=soup_1['parse']\n",
    "text=str(parsing['text'])\n",
    "print(type(text))\n",
    "my_dict = text.count('pizza')\n",
    "\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(int(input())):\n",
    "    string=str(input().strip())\n",
    "    count=0\n",
    "    if bool(re.search(r\"(^[+-]?\\d*\\.\\d+)\",string))==True:\n",
    "        list_1=re.findall(r\"(\\.{1})\",string)\n",
    "        count=len(list_1)\n",
    "        if count>1:\n",
    "            print(\"False\")\n",
    "        else:\n",
    "            print(\"True\")\n",
    "    elif bool(re.match(r\"(^[+-.]\\d+)\",string))==True:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string=str(input())\n",
    "out=re.split(\",\",string)\n",
    "length=len(out)\n",
    "for item in range(length):\n",
    "    if bool(re.search(r\".\",out[item]))==True:\n",
    "        dot_out=re.split(\"\\.\",out[item])\n",
    "        out.remove(out[item])\n",
    "        [out.append(i) for i in dot_out]\n",
    "    else:\n",
    "        pass\n",
    "for i in out:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string=str(input())\n",
    "out=re.split(r\"[,.]\",string)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= '''[1,3,2] '''\n",
    "print(a)\n",
    "n  = ast.literal_eval(a)\n",
    "type(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data='''<person><name>Chuck</name><phone type=\"intl\"> +1 469 655 8235 </phone><email hide=\"yes\"/></person>'''\n",
    "tree= ET.fromstring(data)\n",
    "print('Name:',tree.find('name').text)\n",
    "print('phone',tree.find('phone').text)\n",
    "print('phone',tree.find('phone').get('type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "serviceurl = 'http://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    url = serviceurl + urllib.parse.urlencode({'address': address})\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url)\n",
    "    data = uh.read()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    print(data.decode())\n",
    "    tree = ET.fromstring(data)\n",
    "\n",
    "    results = tree.findall('result')\n",
    "  \n",
    "    lat = results[0].find('geometry').find('location').find('lat').text\n",
    "    lng = results[0].find('geometry').find('location').find('lng').text\n",
    "    location = results[0].find('formatted_address').text\n",
    "\n",
    "    print('lat', lat, 'lng', lng)\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceurl = 'http://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    url = serviceurl + urllib.parse.urlencode({'address': address})\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url)\n",
    "    data = uh.read()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    print(data.decode())\n",
    "    tree = ET.fromstring(data)\n",
    "    results = tree.findall('result')\n",
    "    for item in results:\n",
    "        lat = item.find('geometry').find('location').find('lat').text\n",
    "        lng = item.find('geometry').find('location').find('lng').text\n",
    "        location = item.find('formatted_address').text\n",
    "    print('lat', lat, 'lng', lng)\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://en.wikipedia.org/w/api.php?action=parse&section=0&prop=text&format=json&\"\n",
    "page='pizza'\n",
    "url=base_url+urllib.parse.urlencode({'page':page})\n",
    "soup = urllib.request.urlopen(url).read()\n",
    "print(url)\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location: dallas\n",
      "Retrieving http://maps.googleapis.com/maps/api/geocode/json?address=dallas\n",
      "Retrieved 1725 characters\n",
      "====fail===\n",
      "{\n",
      "   \"results\" : [\n",
      "      {\n",
      "         \"address_components\" : [\n",
      "            {\n",
      "               \"long_name\" : \"Dallas\",\n",
      "               \"short_name\" : \"Dallas\",\n",
      "               \"types\" : [ \"locality\", \"political\" ]\n",
      "            },\n",
      "            {\n",
      "               \"long_name\" : \"Dallas County\",\n",
      "               \"short_name\" : \"Dallas County\",\n",
      "               \"types\" : [ \"administrative_area_level_2\", \"political\" ]\n",
      "            },\n",
      "            {\n",
      "               \"long_name\" : \"Texas\",\n",
      "               \"short_name\" : \"TX\",\n",
      "               \"types\" : [ \"administrative_area_level_1\", \"political\" ]\n",
      "            },\n",
      "            {\n",
      "               \"long_name\" : \"United States\",\n",
      "               \"short_name\" : \"US\",\n",
      "               \"types\" : [ \"country\", \"political\" ]\n",
      "            }\n",
      "         ],\n",
      "         \"formatted_address\" : \"Dallas, TX, USA\",\n",
      "         \"geometry\" : {\n",
      "            \"bounds\" : {\n",
      "               \"northeast\" : {\n",
      "                  \"lat\" : 33.0237921,\n",
      "                  \"lng\" : -96.4637379\n",
      "               },\n",
      "               \"southwest\" : {\n",
      "                  \"lat\" : 32.617537,\n",
      "                  \"lng\" : -96.999347\n",
      "               }\n",
      "            },\n",
      "            \"location\" : {\n",
      "               \"lat\" : 32.7766642,\n",
      "               \"lng\" : -96.79698789999999\n",
      "            },\n",
      "            \"location_type\" : \"APPROXIMATE\",\n",
      "            \"viewport\" : {\n",
      "               \"northeast\" : {\n",
      "                  \"lat\" : 33.0237921,\n",
      "                  \"lng\" : -96.4637379\n",
      "               },\n",
      "               \"southwest\" : {\n",
      "                  \"lat\" : 32.617537,\n",
      "                  \"lng\" : -96.999347\n",
      "               }\n",
      "            }\n",
      "         },\n",
      "         \"place_id\" : \"ChIJS5dFe_cZTIYRj2dH9qSb7Lk\",\n",
      "         \"types\" : [ \"locality\", \"political\" ]\n",
      "      }\n",
      "   ],\n",
      "   \"status\" : \"OK\"\n",
      "}\n",
      "\n",
      "Enter location: \n"
     ]
    }
   ],
   "source": [
    "serviceurl = 'http://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    url = serviceurl + urllib.parse.urlencode({'address': address})\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    \n",
    "    try:\n",
    "        js=json.loads(data, indent=4)\n",
    "    except:\n",
    "        js=None\n",
    "\n",
    "       \n",
    "    if not js or 'status' not in js or js['status']!='OK':\n",
    "        print('====fail===')\n",
    "        print(data)\n",
    "        continue\n",
    "    \n",
    "    extract=js['results'][0] \n",
    "    print(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.8781136\n",
      "-87.6297982\n"
     ]
    }
   ],
   "source": [
    "lat=extract['geometry']['location']['lat']\n",
    "lng=extract['geometry']['location']['lng']\n",
    "print(lat)\n",
    "print(lng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
